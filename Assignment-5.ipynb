{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEwHfnwH2FLCCcQNtZu57c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bg5fH_l58TCy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras.backend as K #imp\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Lambda\n",
        "import tensorflow as tf\n",
        "from keras.utils import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = open(r\"/content/corona.txt\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7CG2V898hHX",
        "outputId": "25972291-6a71-46ac-bb01-bafbaa492e7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/corona.txt' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corona_data = [text for text in data if text.count(' ') >= 2]\n",
        "corona_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUUX6W6f8sgc",
        "outputId": "f27a1b06-316c-4c03-c998-76f5035ce919"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The speed of transmission is an important point of difference between the two viruses. Influenza has a shorter median incubation period (the time from infection to appearance of symptoms) and a shorter serial interval (the time between successive cases) than COVID-19 virus. The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days. This means that influenza can spread faster than COVID-19. \\n',\n",
              " 'Further, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission –transmission of the virus before the appearance of symptoms – is a major driver of transmission for influenza. In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission. \\n',\n",
              " 'The reproductive number – the number of secondary infections generated from one infected individual – is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza. However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult.  ']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize = Tokenizer()\n",
        "vectorize.fit_on_texts(corona_data)\n",
        "corona_data = vectorize.texts_to_sequences(corona_data)\n",
        "\n",
        "total_vocab = sum(len(s) for s in corona_data)\n",
        "word_count = len(vectorize.index_word)+1\n",
        "corona_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuNXzktJ8wAr",
        "outputId": "b06f5bed-b84f-4f70-fc3f-4e73821c5794"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1,\n",
              "  38,\n",
              "  2,\n",
              "  8,\n",
              "  9,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  2,\n",
              "  42,\n",
              "  13,\n",
              "  1,\n",
              "  43,\n",
              "  23,\n",
              "  3,\n",
              "  44,\n",
              "  11,\n",
              "  24,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  1,\n",
              "  14,\n",
              "  25,\n",
              "  48,\n",
              "  10,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  12,\n",
              "  11,\n",
              "  24,\n",
              "  15,\n",
              "  16,\n",
              "  1,\n",
              "  14,\n",
              "  13,\n",
              "  49,\n",
              "  50,\n",
              "  17,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  15,\n",
              "  16,\n",
              "  7,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  9,\n",
              "  51,\n",
              "  10,\n",
              "  18,\n",
              "  19,\n",
              "  52,\n",
              "  20,\n",
              "  28,\n",
              "  7,\n",
              "  3,\n",
              "  6,\n",
              "  1,\n",
              "  15,\n",
              "  16,\n",
              "  9,\n",
              "  29,\n",
              "  20,\n",
              "  30,\n",
              "  53,\n",
              "  31,\n",
              "  3,\n",
              "  32,\n",
              "  54,\n",
              "  55,\n",
              "  17,\n",
              "  4,\n",
              "  5],\n",
              " [56,\n",
              "  8,\n",
              "  33,\n",
              "  1,\n",
              "  57,\n",
              "  29,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  8,\n",
              "  63,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  64,\n",
              "  1,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  21,\n",
              "  9,\n",
              "  11,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  8,\n",
              "  7,\n",
              "  3,\n",
              "  33,\n",
              "  65,\n",
              "  28,\n",
              "  66,\n",
              "  22,\n",
              "  67,\n",
              "  31,\n",
              "  68,\n",
              "  22,\n",
              "  69,\n",
              "  70,\n",
              "  32,\n",
              "  71,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  72,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  10,\n",
              "  76,\n",
              "  77,\n",
              "  78,\n",
              "  79,\n",
              "  30,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  10,\n",
              "  18,\n",
              "  11,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  8],\n",
              " [1,\n",
              "  83,\n",
              "  36,\n",
              "  21,\n",
              "  1,\n",
              "  36,\n",
              "  2,\n",
              "  84,\n",
              "  85,\n",
              "  86,\n",
              "  25,\n",
              "  87,\n",
              "  88,\n",
              "  89,\n",
              "  21,\n",
              "  9,\n",
              "  90,\n",
              "  10,\n",
              "  18,\n",
              "  13,\n",
              "  37,\n",
              "  12,\n",
              "  37,\n",
              "  19,\n",
              "  7,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  91,\n",
              "  17,\n",
              "  7,\n",
              "  3,\n",
              "  92,\n",
              "  93,\n",
              "  7,\n",
              "  94,\n",
              "  4,\n",
              "  5,\n",
              "  12,\n",
              "  3,\n",
              "  23,\n",
              "  22,\n",
              "  95,\n",
              "  96,\n",
              "  12,\n",
              "  14,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  100,\n",
              "  101,\n",
              "  102]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_vocab)\n",
        "print(word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuFTGhml8yiG",
        "outputId": "4f7b50fd-2d1a-4979-e6b4-459f63cf8bd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198\n",
            "103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 2"
      ],
      "metadata": {
        "id": "s6EMlUfK83yk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b. Generate training data\n",
        "# Defining utility to generate context word pairs\n",
        "def cbow_model(data, window_size, total_vocab):\n",
        "    total_length = window_size*2\n",
        "    for text in data:\n",
        "        text_len = len(text)\n",
        "#         print(\"zero\",text)\n",
        "        for idx, word in enumerate(text):\n",
        "#             print(\"first\",idx,word)\n",
        "            context_word = []\n",
        "            target   = []\n",
        "            begin = idx - window_size\n",
        "            end = idx + window_size + 1\n",
        "            context_word.append([\n",
        "                text[i]\n",
        "                for i in range(begin, end)\n",
        "                if 0 <= i < text_len\n",
        "                and i != idx\n",
        "            ])\n",
        "            target.append(word)\n",
        "#             print(\"second\",context_word,target)\n",
        "            contextual = pad_sequences(\n",
        "                context_word,\n",
        "                maxlen=total_length\n",
        "            )\n",
        "            final_target = tf.keras.utils.to_categorical(\n",
        "                target,\n",
        "                total_vocab\n",
        "            )\n",
        "#             print(\"third\",contextual,final_target)\n",
        "            yield(contextual, final_target)"
      ],
      "metadata": {
        "id": "l2gFsSYG88mI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c. train model\n",
        "# Defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    Embedding(\n",
        "        input_dim=total_vocab,\n",
        "        output_dim=100,\n",
        "        input_length=window_size*2\n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    Lambda(\n",
        "        lambda x: K.mean(x, axis=1),\n",
        "        output_shape=(100,)\n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    Dense(\n",
        "        total_vocab,\n",
        "        activation='softmax'\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "0PEhf2dP9KEG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkWHAmzG9Ncf",
        "outputId": "50b93c37-1c46-4c83-898e-6fba8d0efa31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 100)            19800     \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 198)               19998     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39798 (155.46 KB)\n",
            "Trainable params: 39798 (155.46 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam'\n",
        ")"
      ],
      "metadata": {
        "id": "MOYjJwQO9Q-D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    cost = 0\n",
        "    for x, y in cbow_model(corona_data, window_size, total_vocab):\n",
        "        cost += model.train_on_batch(x, y)\n",
        "    print(\"Epoch \", i,\"\\t: \", cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO8SgKvR9U3z",
        "outputId": "66640c58-d0c3-457e-aac1-2f204b006244"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 \t:  1042.0711827278137\n",
            "Epoch  1 \t:  996.6322388648987\n",
            "Epoch  2 \t:  913.9482119083405\n",
            "Epoch  3 \t:  833.1565418243408\n",
            "Epoch  4 \t:  775.1596877574921\n",
            "Epoch  5 \t:  721.7691227197647\n",
            "Epoch  6 \t:  667.5194092988968\n",
            "Epoch  7 \t:  612.5130220651627\n",
            "Epoch  8 \t:  557.8184020519257\n",
            "Epoch  9 \t:  504.7791822552681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = 100\n",
        "vect_file = open('./vectors.txt','w')\n",
        "vect_file.write('{} {}\\n'.format(102, dimensions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P3TTfkb9b96",
        "outputId": "fba8df9c-8bc6-4b91-d6c0-eb8cd22372c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_weights()[0]\n",
        "for text, i in vectorize.word_index.items():\n",
        "    final_vec = ' '.join(map(str, list(weights[i, :])))\n",
        "    vect_file.write('{} {}\\n'.format(text, final_vec))\n",
        "vect_file.close()"
      ],
      "metadata": {
        "id": "csrBvxgB9e0d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# d. Output\n",
        "cbow_output = gensim.models.KeyedVectors.load_word2vec_format(\n",
        "    'vectors.txt',\n",
        "    binary=False\n",
        ")\n",
        "cbow_output.most_similar(positive=['speed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpfoMULj9iy5",
        "outputId": "b92cb051-51a6-4e21-bf25-bbc9cd466ad3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('–transmission', 0.8569073677062988),\n",
              " ('difference', 0.8411794304847717),\n",
              " ('number', 0.7541648745536804),\n",
              " ('before', 0.6687363982200623),\n",
              " ('two', 0.6466360688209534),\n",
              " ('symptoms', 0.6455479264259338),\n",
              " ('reproductive', 0.6390285491943359),\n",
              " ('driver', 0.6374366283416748),\n",
              " ('serial', 0.6340043544769287),\n",
              " ('of', 0.6224905848503113)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}